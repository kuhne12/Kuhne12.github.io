<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><title>cs231n 学习笔记（11）可视化与理解 | Kuhne</title><meta name="keywords" content="计算机视觉,深度学习"><meta name="author" content="Kuhne"><meta name="copyright" content="Kuhne"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#f7f9fe"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-touch-fullscreen" content="yes"><meta name="apple-mobile-web-app-title" content="cs231n 学习笔记（11）可视化与理解"><meta name="application-name" content="cs231n 学习笔记（11）可视化与理解"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#f7f9fe"><meta property="og:type" content="article"><meta property="og:title" content="cs231n 学习笔记（11）可视化与理解"><meta property="og:url" content="https://kuhne.gitee.io/kuhne.gitee.io/posts/1af2ae7a.html"><meta property="og:site_name" content="Kuhne"><meta property="og:description" content="可视化卷积神经网络 &amp;#x2F; 梯度上升 &amp;#x2F; 风格迁移"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/img/2901e2f51d643b321c61e158805fe248.jpeg"><meta property="article:author" content="Kuhne"><meta property="article:tag"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/img/2901e2f51d643b321c61e158805fe248.jpeg"><meta name="description" content="可视化卷积神经网络 &amp;#x2F; 梯度上升 &amp;#x2F; 风格迁移"><link rel="shortcut icon" href="/img/head2.png"><link rel="canonical" href="https://kuhne.gitee.io/kuhne.gitee.io/posts/1af2ae7a"><link rel="preconnect" href="//npm.elemecdn.com"/><link rel="preconnect" href="//npm.onmicrosoft.cn"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="xxx"/><meta name="baidu-site-verification" content="code-xxx"/><meta name="msvalidate.01" content="xxx"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/@fancyapps/ui@5.0.20/dist/fancybox/fancybox.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/swiper/swiper.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  linkPageTop: undefined,
  peoplecanvas: {"enable":true,"img":"https://upload-bbs.miyoushe.com/upload/2023/09/03/125766904/ee23df8517f3c3e3efc4145658269c06_5714860933110284659.png"},
  postHeadAiDescription: undefined,
  diytitle: undefined,
  LA51: {"enable":true,"ck":"3Fpd8lKaw5wGj1Fj","LingQueMonitorID":null},
  greetingBox: {"enable":true,"default":"晚上好👋","list":[{"greeting":"晚安😴","startTime":0,"endTime":5},{"greeting":"早上好鸭👋, 祝你一天好心情！","startTime":6,"endTime":9},{"greeting":"上午好👋, 状态很好，鼓励一下～","startTime":10,"endTime":10},{"greeting":"11点多啦, 在坚持一下就吃饭啦～","startTime":11,"endTime":11},{"greeting":"午安👋，中午要好好休息一下～","startTime":12,"endTime":14},{"greeting":"🌈充实的一天辛苦啦！","startTime":14,"endTime":18},{"greeting":"19点喽, 奖励一顿丰盛的大餐吧🍔。","startTime":19,"endTime":19},{"greeting":"晚上好👋, 在属于自己的时间好好放松😌~","startTime":20,"endTime":24}]},
  twikooEnvId: 'https://twikoo-api-pearl.vercel.app',
  commentBarrageConfig:{"enable":true,"maxBarrage":1,"barrageTime":4000,"accessToken":"","mailMd5":""},
  root: '/',
  preloader: {"source":3},
  friends_vue_info: undefined,
  navMusic: true,
  mainTone: {"mode":"both","api":"https://122.51.174.211:3000/api?img=","cover_change":true},
  authorStatus: {"skills":["🐟 上班摸鱼佼佼者"]},
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简","rightMenuMsgToTraditionalChinese":"转为繁体","rightMenuMsgToSimplifiedChinese":"转为简体"},
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":330},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    simplehomepage: true,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"copy":true,"copyrightEbable":false,"limitCount":50,"languages":{"author":"作者: Kuhne","link":"链接: ","source":"来源: Kuhne","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","copySuccess":"复制成功，复制和转载请标注本文地址"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#425AEF","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.min.js',
      css: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  shortcutKey: {"enable":true,"delay":100,"shiftDelay":200},
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  configTitle: 'Kuhne',
  title: 'cs231n 学习笔记（11）可视化与理解',
  postAI: '',
  pageFillDescription: 'cs231n 学习笔记（11）可视化与理解, 一、问题描述, 二、理解卷积神经网络, 2.1 CNN 第一层, 2.2 CNN 中间层, 最大激活块（Maximally Activating Patches）, 2.3 CNN 最后层, 三、 理解像素, 3.1 遮挡实验, 3.2 显著图, 3.3引导式反向传播 （guided backprop）, 3.4 梯度上升（ Gradient Ascent）, 四、DeepDream, 五、风格迁移, 5.1 特征反演（Feature Inversion）, 5.2 纹理生成, 神经纹理生成（Neural Texture Synthesis）, 5.3 风格迁移（Style Transfer）, 5.4 快速风格迁移（Fast style Transfer）, 总结学习笔记可视化与理解本节将讨论如何可视化理解卷积神经网络一问题描述现在有这样一个问题的内部真正的原理是什么我们已经知道了如何训练卷积神经网络以及如何构建不同类型架构的网络来解决不同的问题但现在还有一个疑问这些神经网络的内部到底是怎么运行的它们是如何让完成各自特定的工作的它们寻找的特征是什么到目前为止我们一直将看作一个黑箱包含原始像素的输入图像从黑箱的一端进入经过了很多层且进行了许多不同的转换在的输出端会得到一些类的分值或是别的可以被理解的输出比如边框位置标记像素等但问题是中间层的作用是什么二理解卷积神经网络第一层相对来说的第一层会比较简单一般来说第一层卷积层由卷积核组成例如在中第一个卷积层由许多卷积核个组成每个卷积核的尺寸是这些卷积核会在输入图像上不断滑动获取图像块与卷积核的数量积得到第一层的输出结果我们可以简单地将学习到的卷积核可视化来得知卷积核正在寻找什么把中的每个卷积核看作是一个通道的图像将个卷积核进行可视化如下图所示可以看到这些层中的卷积核正在寻找有向边比如明暗线条从不同的角度和位置来观察输入图像也可以看到一个卷积核中存在完全不同的颜色比如绿色和粉色橙色和蓝色相当于第一个卷积层在尝试去做一些类似于人类视觉系统早期阶段的工作有趣的是无论链接的体系结构或者训练数据类型是什么在第一层卷积层总是能得到类似的结果中间层这部分不明白的地方比较多写的几乎是逐字稿了可视化权重如果对中间的卷积层做相同的可视化会发现对应图像的可解释性会差很多第二层的权重会经过激活函数或其他的非线性激活函数接收了个通道的输入并且使用个卷积核进行的卷积我们不能直接将这些权重进行可视化因为输入图像的深度是维的且每个卷积核的尺寸为共有个卷积核这里的做法是对于单一的的卷积核画出个的灰度图一共画组下图的灰度图像显示了第二层某个卷积核的权重因为有个输出所以第二层卷积层有个形状为的卷积核将卷积核权重进行可视化后可以发现他们具有一些空间结构但并不能直接观察到很有价值的信息因为这些卷积核并没有直接连接到输入图像所以我们需要想出一些更奇特的方法用来理解中间卷积层究竟在做什么可视化激活图中间层可视化权重的解释性并不是很强而可视化中间层的在某些情况下更具可解释性再次以为例的第个卷积层提供了的张量我们可以将其转化为个的灰度图像这能让我们意识到需要寻找的特征在输入中是什么样的下面是可视化的一个具体例子可以看到中间高亮的图像似乎在匹配输入的图像寻找类似于人脸的东西但其他的大部分图像都是噪声最大激活块对于可视化中间层可以做的另一件事情是可视化输入图像中不同类型的图像块可以最大程度地激活不同的特征不同的神经元比如选取的第个卷积层的第个激活图共个随后输入很多图像通过卷积神经网络分别记录第个激活图的值这个特征图上部分值会被输入图片集最大激活由于每个神经元的感受野有限我们可以画出这些被最大激活的神经元对应在原始输入图片的小块通过这些小块观察不同的神经元在寻找哪些信息下面是一些来自特定神经元输入图像块的例子其中每一行都是某个神经元被最大激活对应的图片块可以看到有的神经元在寻找类似眼睛的东西有的在寻找弯曲的曲线等如果不使用的激活图而是更后面的卷积层由于卷积核视野扩大寻找的特征也会更加复杂比如人脸相机等对应下图的下面部分一个单层的卷积核对应一行多个就形成了上图意味着这层卷积核关注的是原图的什么可能是眼睛脸最后层现在来讨论模型的最后一层的最后一层可能会得到个类的得分情况来告知数据集中每个类的得分在最后一层之前一般会存在全连接层用维的特征向量来表示图像然后将其输入到最后一层来预测最终类的得分另一种用于可视化和理解的方法是尝试理解神经网络的最后一层可以通过来检测一些图像并为每一幅图像标记对应的维向量试着可视化最后一层隐层最近邻我们可能会看到尝试使用最近邻法最近邻法可以在像素空间中寻找近邻比如之前在数据集上使用法会发现找的到图像和查询的图像看起来非常相似但不一定是一类事物与其根据像素空间来计算近邻不如在由卷积得到的维的特征空间中计算近邻如下图所示有些图像在像素空间中并不类似比如大象的第一张和第四张但由于是在由计算得到的维特征空间上进行计算最终会认为两张图象直接非常相似大概意思就是比起在原始像素上使用不如在卷积得到的向量上使用说明了维的特征空间能捕捉到图像中的语义内容降维另一种用于观察最后一层的方法是降维通过将维的特征向量压缩到二维空间以便更加直观的可视化特征空间除了还有一种更强大的降维算法也就是的缩写它是以一种在深度学习领域常被使用的用于可视化特征的非线性降维方法下图是的一个应用实例展示了在数据集上的降维也就是手写数字数据集可以看到降维后的数据集可以更清晰的展现出集群的特点这些集群对应了数据集中的数据所以我们现在就可以做类似的可视化工作也就是在图像分类器网络的最后一层上应用降维具体来说就是提取大量图像并让他们在上运行记录每个图像在网络最后一层产生的维特征向量数量很大通过把维的特征空间压缩至维随后在维的特征空间中布局网格并观察维特征空间网格每个位置会出现什么类型的图像通过这种做法可以粗略地感受到学习到的特征空间的几何结构粗略版本通过粗略版本可以观察到左下角都是一些绿色的东西而右上角偏蓝高清版本三理解像素遮挡实验遮挡实验是为了弄清楚究竟是输入图像的哪部分导致神经网络做出了最终的分类决策以包含了一头大象的图片为例实验的具体方法是遮挡住图像的某个部分替换为数据集的平均像素值然后将图像输入网络记录遮挡图像的预测概率随后将此遮挡块滑过所有位置重复所有步骤最后绘制图像的热力图如下图所示热力图显示了在该位置设定遮挡块时对应的预测概率为多少如果遮挡了图像的某部分导致神经网络分值急剧变化那么该遮挡区域可能对模型分类决策起到非常重要的作用图中颜色越深的地方代表预测概率越低以大象为例如果遮住大象的脸部预测概率会急剧下降说明大象的脸部像素对神经网络做出决策有很重要的作用显著图给出一只狗的输入图像以及狗的预测类标签我们想知道输入图像中的哪部分像素对于分类是最重要的除了遮挡实验显著图是从另一个角度解决这个问题的方法具体做法是计算分类得分相对于图像像素的梯度这将告诉我们在一阶近似意义上对于输入图片的每个像素进行小小的扰动那么相应分类的分值会有多大的变化当通过显著图的方法运行小狗的图像能很方便地看出图中小狗的轮廓这表示网络正在寻找的特征可能在这些像素之间如果对不同的图像做相同地操作就能发现神经网络在寻找合适的区域进行语义分割的时候也可以运用显著图的方法可以在没有任何标签的情况下可以运用显著图进行语义分割引导式反向传播显著图是使用分类得分对图片上的像素求导得出对分类决策影响较大的像素而引导式反向传播是使用某一层的特定神经元的值对像素求导这样就能观察图像的像素对特定神经元的影响但是这里的反向传播是引导式的即函数反向传播时只回传大于的梯度如下图所示虽然这样做很奇怪但是效果很好图像很清晰当使用引导式反向传播而不是用定期反向传播时更容易获得更清晰的图像来告知图像中的哪部分像素影响了特定的神经元我们把引导式反向传播计算的梯度可视化和最大激活块进行对比发现这两者的表现很相似下图左边是最大激活块每一行代表一个神经元右侧是该神经元计算得到的对原始像素的引导式反向传播梯度以第一行为例最大激活该神经元的图像块都是一些圆形的区域这表明该神经元可能在寻找圆形状物体然后观察右边发现的确是圆形区域的像素会影响的神经元的值梯度上升从以上讲述的几个方法中我们了解到如何查看对神经元影响最大的像素如果我们在一些输入图像中移除这种依赖性那什么类型的输入才会激活该神经元我们可以通过梯度上升算法来解决这个问题我们总在训练神经网络时使用梯度下降来使最小化而现在我们想要在图像上执行梯度上升来合成图像以尝试最大化某些中间神经元和类别的分值来改变像素值在执行梯度上升的过程中我们不再优化权重而是让权重保持不变尝试改变一些图像的像素使该神经元的值或对应类的分值最大化除此之外我们还需要用到正则项以阻止生成的图像过拟合而生成很奇怪的东西生成图像具备两个属性使最大程度地激活分类得分或神经元的值使我们希望这个生成的图像看起来是自然的正则项强制生成的图像看起来是自然的图像具体方法是把初始图象初始化为或者添加高斯噪声然后通过神经网络重复传入图像并计算神经元分值反向传播计算神经元分值对图像像素的梯度更新图像以使神经元分值最大化不断重复上述步骤直到图像可以理解为止上面讨论到为图像进行正则化一个比较常见的正则化方法是通过正则化来约束像素针对分类得分生成的图片如下所示用肉眼很难看清楚但是能看出个大概除了正则化外还能使用一些方法来优化正则比如对生成的图像进行高斯模糊处理将像素值特别小或梯度值特别小的值去掉这些方法会使生成的图像更清晰也可以针对某个神经元进行梯度上升层数越高生成的结构越复杂如下图所示添加多模态可视化可以提供更好的结果加上更仔细的正则化中心偏差通过优化的特征而不是原始像素会得到更加自然的图像通过图像像素的梯度来合成图像的想法其实非常强大其中一个有趣的想法就是愚弄网络即选取一些任意的图像然后告诉网络我们希望最大化另一类事物的分值然后修改原图的像素最后网络会将该图像分类成零一类事物而图像看上去却没多大变化四我们可以做的另一件基于梯度的图像优化是这谷歌发布的一篇博客文章的内容仍然利用梯度上升的原理不再是通过最大化神经元激活来合成图片而是直接放大某些层的神经元激活特征想法是输入图像通过神经网络运行到某一层接着进行反向传播并设置该层的梯度等于激活值然后反向传播到图像并不断地更新图像上述步骤试图放大神经网络在图像中检测到的特征无论那层存在什么特征都将其梯度设为特征值使神经网络放大它在图像中检测到的特征这种方法同样可以用于最大化图像在该层中的范数做完一切后输入一张天空的图像可以把网络中学到的特征在原图像上生成现在特征已经被放置在了天空的图像上通过这个过程特征得到了放大可以看到很多突变物体对神经网络不同层做同样的操作也会得到差不多的结果下图选择的是神经网络一个较低层似乎正在计算边缘或者漩涡之类的东西如果长时间运行并且进行多尺度处理可能得到很诡异的图像下面是在上运行后的结果数据集包含了种不同的场景图像五风格迁移特征反演特征反演是为了查看不同层的特征向量能保留多少原始的图片信息具体过程是向种喂入一张图像选取其在某一层产生的特征向量随后根据该特征向量重构图像重构后的图像会提供一些神经网络捕获到的图像类型信息可以通过梯度上升和正则化做到与其最大化某些分值不如最小化特征向量之间的距离并且在生成图像的特征之间尝试合成一个新的相匹配的图像全变差正则化将左右相邻像素之间的差异拼凑成上下相邻尝试增加生成图像中特殊的平滑度用这种方法我们可以看到不同层的特征向量所包含的信息完整度最左侧是原始图像右侧是根据不同层记录的特征生成的图像这能让我们了解到这张图像在神经网络不同层的信息存储量在层可以根据特征向量几乎无损地恢复出原图片但是尝试从重构图像时可以看到图像的一般空间结构被保留了下来仍可以分辨出大象苹果和香蕉但是许多低层次的细节并比如纹理颜色在神经网路的较高层更容易损失纹理生成纹理合成在计算机图形学里是一个老问题比如给定一些纹理的输入图像想要生成更大块的相同纹理的图像如下图所示算法在纹理生成问题的表现非常好但是没有神经网络这里采用的是非常简单的方法即按照扫描线一次一个像素地遍历生成图像然后根据已经生成的像素查看当前像素周围的邻域并在输入图像地图像块中计算近邻然后从输入图像中复制像素如果使用的是复杂纹理直接从输入图像的图像块复制像素的方法可能会行不通有一篇论文试图将神经网络的特征应用到纹理合成问题上最终将这个问题转化为梯度上升的过程类似于其中各种各样的指的是物体上的特征格莱姆矩阵为了在神经网络上进行纹理合成使用了格莱姆矩阵将输入图像传递给抽取他们在某层的卷积特征假设卷积特征大小为可以将其看作是个维的特征向量用于描述图像在这点的外观做矩阵乘法可以得到一个的矩阵然后对激活图中任意两个维向量的组合都可以求出这样一个矩阵把这些矩阵求和并平均就是格莱姆矩阵格莱姆矩阵告诉我们两个点代表的不同特征的同现关系矩阵中位置索引为的元素值非常大这意味着这两个输入向量的位置索引为和的元素值非常大这以某种方式捕获了一些二阶统计量即映射特征图中的哪些特征倾向于在空间的不同位置一起激活为什么不使用协方差矩阵或类似的方法而是使用格莱姆矩阵格莱姆矩阵其实是之间的偏心协方差矩阵即没有减去均值的协方差矩阵其计算了每个通道特征之间的相关性考察哪些特征是此消彼长的哪些特征是同时出现的我们认为格莱姆矩阵度量了图片中的纹理特性并且不包含图像的结构信息因为我们对图像中的每一点所对应的特征向量取平均值它只是捕获特征间的二阶同现统计量这最终是一个很好的纹理描述符事实上使用协方差矩阵代替格莱姆矩阵也能取得很好的效果但是格莱姆矩阵有更高效的计算方法将激活图张量展开成的形式然后将其乘以其转置即得到矩阵神经纹理生成当我们有了格莱姆矩阵这一度量图像纹理特性的工具后就可以使用类似于梯度上升算法来产生特定纹理的图像算法流程为使用数据集预训练一个网络把含有纹理的图像输入到网络进行前向传播记录其每一层的激活图计算每一层的格莱姆矩阵给出特征的外积在随机噪声中初始化生成图像通过生成图像计算每一层的格拉姆矩阵计算损失格莱姆矩阵之间距离的加权和反向传播得到图片的梯度根据梯度上升一点点更新图像的像素重复步骤最终会生成与纹理图像相匹配的纹理图像效果如下上图说明如果以更高层格莱姆矩阵的距离作为损失函数那么生成图像就会更好地重建图像的纹理结构这是由于更高层的神经元具有更大的感受野导致的风格迁移结合特征反演和纹理生成就可以实现所谓的风格迁移在风格迁移中我们把两张图像作为输入图像第一步将其中一张图像做为内容图像他将引导生成图像的主体将零一幅图像作为风格图像负责生成图像的纹理或风格然后共同做特征识别最小化内容图像的特征重构损失以及风格图像的格莱姆矩阵损失完成以上步骤就能获得非常不错的图像基本架构如下在这个框架中使用随机噪声初始化生成图像同时优化特征反演和纹理生成的损失函数生成图像与内容图像激活特征向量的距离以及与风格图像格莱姆矩阵的距离的加权和计算图像上的像素梯度重复这些步骤在生成图像上执行梯度上升经过一些迭代后会生成风格迁移后的图像这样生成图像既具有内容图像的空间结构又具有风格图像的纹理结构由于网络使用的总损失是特征反演和纹理生成的两部分损失的加权和所以调整这个加权值可以得到不同风格的输出也可以改变风格图像的尺寸此外也可以使用不同风格的格莱姆矩阵的加权和来生成多风格图实现代码点击这里快速风格迁移但是风格迁移算法有一个问题算法的效率特别低为了生成新图像需要在预训练网络中计算很多前向传播和反向传播特别是为了生成高分辨率的图像每个图像的前向传播和反向传播都需要大量的计算和内存解决方法是训练另一种神经网络来进行风格迁移的工作有一篇研究提出了这么一个想法在一开始就训练好想要迁移的风格并不是为每个图象运行一个单独的优化程序而是训练一个可以输入内容图像的前馈网络直接输出风格迁移后的结果训练前馈神将网络的方法是在训练期间计算相同内容图像和风格图像的损失然后使用相同梯度来更新前馈神经网络的权重一旦训练完成只需在训练好的网络上进行单一的前向传播训练过程可能需要耗费几个小时的时间但是一旦训练完成生成风格迁移图像的速度会很快实现代码点击这里总结理解激活值在激活值的基础上理解这些神经元在寻找什么特征方法有最邻近降维最大化图像块遮挡梯度使用梯度上升合成新图像来理解特征的意义比如显著图类可视化愚弄图像特征反演风格迁移特征反演纹理生成',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-03-04 13:22:06',
  postMainColor: '',
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#18171d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#f7f9fe')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(e => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Kuhne" type="application/atom+xml">
</head><body data-type="anzhiyu"><div id="web_bg"></div><div id="an_music_bg"></div><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload" alt="加载头像" src="https://kuhne.gitee.io/kuhne.gitee.io/img/head.jpg"/><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.getElementById('loading-box').classList.add("loaded");
  },
  initLoading: () => {
    document.getElementById('loading-box').classList.remove("loaded")
  }
}
window.addEventListener('load',()=> { preloader.endLoading() })
setTimeout(function(){preloader.endLoading();},10000)

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.10/progress_bar/progress_bar.css"/><script async="async" src="https://cdn.cbd.int/pace-js@1.2.4/pace.min.js" data-pace-options="{ &quot;restartOnRequestAfter&quot;:false,&quot;eventLag&quot;:false}"></script><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><div id="nav-group"><span id="blog_name"><div class="back-home-button"><i class="anzhiyufont anzhiyu-icon-grip-vertical"></i><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://blog.anheyu.com/" title="博客"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/favicon.ico" alt="博客"/><span class="back-menu-item-text">博客</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">项目</div><div class="back-menu-list"><a class="back-menu-item" href="/null" title="暂无"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://image.anheyu.com/favicon.ico" alt="暂无"/><span class="back-menu-item-text">暂无</span></a></div></div></div></div><a id="site-name" href="/" accesskey="h"><div class="title">Kuhne</div><i class="anzhiyufont anzhiyu-icon-house-chimney"></i></a></span><div class="mask-name-container"><div id="name-container"><a id="page-name" href="javascript:anzhiyu.scrollToDest(0, 500)">PAGE_NAME</a></div></div><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/music/?id=883682303&amp;server=netease&amp;type=playlist"><i class="anzhiyufont anzhiyu-icon-music faa-tada" style="font-size: 0.9em;"></i><span> 音乐馆</span></a></li></ul></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/essay/"><span> 闲言碎语</span></a></div></div></div><div id="nav-right"><div class="nav-button" id="randomPost_button"><a class="site-page" onclick="toRandomPost()" title="随机前往一个文章" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-dice"></i></a></div><div class="nav-button" id="search-button"><a class="site-page social-icon search" href="javascript:void(0);" title="搜索🔍" accesskey="s"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span> 搜索</span></a></div><input id="center-console" type="checkbox"/><label class="widget" for="center-console" title="中控台" onclick="anzhiyu.switchConsole();"><i class="left"></i><i class="widget center"></i><i class="widget right"></i></label><div id="console"><div class="console-card-group-reward"><ul class="reward-all console-card"><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png" target="_blank"><img class="post-qr-code-img" alt="微信" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png" target="_blank"><img class="post-qr-code-img" alt="支付宝" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div><div class="console-card-group"><div class="console-card-group-left"><div class="console-card" id="card-newest-comments"><div class="card-content"><div class="author-content-item-tips">互动</div><span class="author-content-item-title"> 最新评论</span></div><div class="aside-list"><span>正在加载中...</span></div></div></div><div class="console-card-group-right"><div class="console-card tags"><div class="card-content"><div class="author-content-item-tips">兴趣点</div><span class="author-content-item-title">寻找你感兴趣的领域</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/2022CVPR/" style="font-size: 1.05rem;">2022CVPR<sup>2</sup></a><a href="/tags/Git/" style="font-size: 1.05rem;">Git<sup>1</sup></a><a href="/tags/Kaggle/" style="font-size: 1.05rem;">Kaggle<sup>2</sup></a><a href="/tags/Linux/" style="font-size: 1.05rem;">Linux<sup>2</sup></a><a href="/tags/PyTorch/" style="font-size: 1.05rem;">PyTorch<sup>9</sup></a><a href="/tags/Python/" style="font-size: 1.05rem;">Python<sup>6</sup></a><a href="/tags/Pytorch/" style="font-size: 1.05rem;">Pytorch<sup>1</sup></a><a href="/tags/SpringCloud/" style="font-size: 1.05rem;">SpringCloud<sup>9</sup></a><a href="/tags/Vue/" style="font-size: 1.05rem;">Vue<sup>3</sup></a><a href="/tags/nginx/" style="font-size: 1.05rem;">nginx<sup>1</sup></a><a href="/tags/pycharm/" style="font-size: 1.05rem;">pycharm<sup>1</sup></a><a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" style="font-size: 1.05rem; font-weight: 500; color: var(--anzhiyu-lighttext)">人工智能<sup>21</sup></a><a href="/tags/%E4%BD%9C%E4%B8%9A/" style="font-size: 1.05rem;">作业<sup>8</sup></a><a href="/tags/%E5%8A%A0%E5%AF%86/" style="font-size: 1.05rem;">加密<sup>1</sup></a><a href="/tags/%E5%90%8E%E7%AB%AF/" style="font-size: 1.05rem;">后端<sup>3</sup></a><a href="/tags/%E5%9F%BA%E7%A1%80/" style="font-size: 1.05rem;">基础<sup>12</sup></a><a href="/tags/%E5%B7%A5%E5%85%B7/" style="font-size: 1.05rem;">工具<sup>3</sup></a><a href="/tags/%E5%BD%92%E7%BA%B3/" style="font-size: 1.05rem;">归纳<sup>3</sup></a><a href="/tags/%E6%95%99%E7%A8%8B/" style="font-size: 1.05rem;">教程<sup>10</sup></a><a href="/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/" style="font-size: 1.05rem;">服务器<sup>1</sup></a><a href="/tags/%E6%9C%AA%E5%AE%8C%E6%88%90/" style="font-size: 1.05rem;">未完成<sup>1</sup></a><a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 1.05rem;">机器学习<sup>21</sup></a><a href="/tags/%E6%A8%A1%E5%9E%8B%E5%A4%8D%E7%8E%B0/" style="font-size: 1.05rem;">模型复现<sup>8</sup></a><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 1.05rem; font-weight: 500; color: var(--anzhiyu-lighttext)">深度学习<sup>15</sup></a><a href="/tags/%E7%BD%91%E9%A1%B5%E5%89%8D%E7%AB%AF/" style="font-size: 1.05rem;">网页前端<sup>4</sup></a><a href="/tags/%E8%80%83%E7%A0%94/" style="font-size: 1.05rem;">考研<sup>1</sup></a><a href="/tags/%E8%A7%86%E8%A7%89%E5%85%B3%E7%B3%BB%E6%8E%A2%E6%B5%8B/" style="font-size: 1.05rem;">视觉关系探测<sup>1</sup></a><a href="/tags/%E8%A7%86%E8%A7%89%E9%97%AE%E7%AD%94/" style="font-size: 1.05rem;">视觉问答<sup>1</sup></a><a href="/tags/%E8%A7%86%E9%A2%91%E9%97%AE%E7%AD%94/" style="font-size: 1.05rem;">视频问答<sup>1</sup></a><a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" style="font-size: 1.05rem;">计算机视觉<sup>12</sup></a><a href="/tags/%E8%AE%BA%E6%96%87/" style="font-size: 1.05rem;">论文<sup>4</sup></a></div></div><hr/></div></div><div class="console-card history"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-box-archiv"></i><span>文章</span></div><div class="card-archives"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-archive"></i><span>归档</span><a class="card-more-btn" href="/archives/" title="查看更多">
    <i class="anzhiyufont anzhiyu-icon-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/09/"><span class="card-archive-list-date">九月 2023</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/02/"><span class="card-archive-list-date">二月 2023</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/09/"><span class="card-archive-list-date">九月 2022</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/08/"><span class="card-archive-list-date">八月 2022</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">12</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/07/"><span class="card-archive-list-date">七月 2022</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">11</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/06/"><span class="card-archive-list-date">六月 2022</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">8</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/05/"><span class="card-archive-list-date">五月 2022</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">16</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/04/"><span class="card-archive-list-date">四月 2022</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">8</span><span>篇</span></div></a></li></ul></div><hr/></div></div></div><div class="button-group"><div class="console-btn-item"><a class="darkmode_switchbutton" title="显示模式切换" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-moon"></i></a></div><div class="console-btn-item" id="consoleHideAside" onclick="anzhiyu.hideAsideBtn()" title="边栏显示控制"><a class="asideSwitch"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></a></div><div class="console-btn-item on" id="consoleCommentBarrage" onclick="anzhiyu.switchCommentBarrage()" title="热评开关"><a class="commentBarrage"><i class="anzhiyufont anzhiyu-icon-message"></i></a></div><div class="console-btn-item" id="consoleMusic" onclick="anzhiyu.musicToggle()" title="音乐开关"><a class="music-switch"><i class="anzhiyufont anzhiyu-icon-music"></i></a></div><div class="console-btn-item" id="consoleKeyboard" onclick="anzhiyu.keyboardToggle()" title="快捷键开关"><a class="keyboard-switch"><i class="anzhiyufont anzhiyu-icon-keyboard"></i></a></div></div><div class="console-mask" onclick="anzhiyu.hideConsole()" href="javascript:void(0);"></div></div><div class="nav-button" id="nav-totop"><a class="totopbtn" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i><span id="percent" onclick="anzhiyu.scrollToDest(0,500)">0</span></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" title="切换"><i class="anzhiyufont anzhiyu-icon-bars"></i></a></div></div></div></nav><div id="post-info"><div id="post-firstinfo"><div class="meta-firstline"><a class="post-meta-original">原创</a><span class="post-meta-categories"><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-inbox post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url">深度学习</a></span><span class="article-meta tags"><a class="article-meta__tags" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>计算机视觉</span></a><a class="article-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>深度学习</span></a></span></div></div><h1 class="post-title" itemprop="name headline">cs231n 学习笔记（11）可视化与理解</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="anzhiyufont anzhiyu-icon-calendar-days post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" itemprop="dateCreated datePublished" datetime="2022-07-15T10:06:28.000Z" title="发表于 2022-07-15 18:06:28">2022-07-15</time><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-history post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" itemprop="dateCreated datePublished" datetime="2023-03-04T05:22:06.611Z" title="更新于 2023-03-04 13:22:06">2023-03-04</time></span></div><div class="meta-secondline"><span class="post-meta-separator"></span><span class="post-meta-wordcount"><i class="anzhiyufont anzhiyu-icon-file-word post-meta-icon" title="文章字数"></i><span class="post-meta-label" title="文章字数">字数总计:</span><span class="word-count" title="文章字数">6.7k</span><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-clock post-meta-icon" title="阅读时长"></i><span class="post-meta-label" title="阅读时长">阅读时长:</span><span>20分钟</span></span><span class="post-meta-separator"></span><span class="post-meta-pv-cv" id="" data-flag-title="cs231n 学习笔记（11）可视化与理解"><i class="anzhiyufont anzhiyu-icon-fw-eye post-meta-icon"></i><span class="post-meta-label" title="阅读量">阅读量:</span><span id="busuanzi_value_page_pv"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-spin"></i></span></span><span class="post-meta-separator">       </span><span class="post-meta-position" title="作者IP属地为杭州"><i class="anzhiyufont anzhiyu-icon-location-dot"></i>杭州</span><span class="post-meta-separator"></span><span class="post-meta-commentcount"><i class="anzhiyufont anzhiyu-icon-comments post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/posts/1af2ae7a.html#post-comment" tabindex="-1"><span id="twikoo-count"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-spin"></i></span></a></span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section><div id="post-top-cover"><img class="nolazyload" id="post-top-bg" src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/img/2901e2f51d643b321c61e158805fe248.jpeg"></div></header><main id="blog-container"><div class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container" itemscope itemtype="https://kuhne.gitee.io/kuhne.gitee.io/posts/1af2ae7a.html"><header><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url">深度学习</a><a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" tabindex="-1" itemprop="url">计算机视觉</a><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" tabindex="-1" itemprop="url">深度学习</a><h1 id="CrawlerTitle" itemprop="name headline">cs231n 学习笔记（11）可视化与理解</h1><span itemprop="author" itemscope itemtype="http://schema.org/Person">Kuhne</span><time itemprop="dateCreated datePublished" datetime="2022-07-15T10:06:28.000Z" title="发表于 2022-07-15 18:06:28">2022-07-15</time><time itemprop="dateCreated datePublished" datetime="2023-03-04T05:22:06.611Z" title="更新于 2023-03-04 13:22:06">2023-03-04</time></header><h1>cs231n 学习笔记（11）可视化与理解</h1>
<p><em>2022 / 7 / 12</em></p>
<blockquote>
<p>本节将讨论如何可视化理解卷积神经网络</p>
</blockquote>
<h2 id="一、问题描述">一、问题描述</h2>
<p>现在有这样一个问题：CNN 的内部真正的原理是什么？</p>
<p>我们已经知道了如何训练卷积神经网络，以及如何构建不同类型架构的网络来解决不同的问题，但现在还有一个疑问，这些<strong>神经网络的内部到底是怎么运行的</strong>？<strong>它们是如何让完成各自特定的工作的</strong>？<strong>它们寻找的特征是什么</strong>？</p>
<p>到目前为止，我们一直将 CNN 看作一个<strong>黑箱</strong>，包含原始像素的输入<strong>图像</strong>，从黑箱的一端进入，经过了很多 CNN 层，且进行了许多不同的转换，在 CNN 的输出端会得到一些<strong>类的分值</strong>，或是别的可以被理解的输出（比如边框位置、标记像素等），但问题是，中间层的作用是什么？</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/12/141015-042a0.png" alt=""></p>
<h2 id="二、理解卷积神经网络">二、理解卷积神经网络</h2>
<h3 id="2-1-CNN-第一层">2.1 CNN 第一层</h3>
<p>相对来说 CNN 的第一层会比较简单，一般来说第一层卷积层由卷积核组成，例如在 AlexNet 中，第一个卷积层由许多卷积核（64 个）组成，每个卷积核的尺寸是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><mn>11</mn><mo>×</mo><mn>11</mn></mrow><annotation encoding="application/x-tex">3\times11\times11</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">11</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">11</span></span></span></span> ，这些卷积核会在输入图像上不断滑动，获取图像块与卷积核的数量积，得到第一层的输出结果。</p>
<p>我们可以简单地<strong>将学习到的卷积核可视化，来得知卷积核正在“寻找”什么</strong>：把 AlexNet 中的每个卷积核看作是一个 3 通道 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>11</mn><mo>×</mo><mn>11</mn></mrow><annotation encoding="application/x-tex">11\times11</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">11</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">11</span></span></span></span> 的图像，将 64 个卷积核进行可视化，如下图所示：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/12/144342-5cf4d.png" alt=""></p>
<p>可以看到，这些层中的卷积核正在寻找<strong>有向边</strong>（比如明暗线条） ，从不同的角度和位置来观察输入图像，也可以看到一个卷积核中存在完全不同的颜色（比如绿色和粉色、橙色和蓝色），相当于第一个卷积层在尝试去做一些<strong>类似于人类视觉系统早期阶段的工作</strong>。有趣的是，无论链接的体系结构或者训练数据类型是什么，在第一层卷积层总是能得到类似的结果。</p>
<h3 id="2-2-CNN-中间层">2.2 CNN 中间层</h3>
<blockquote>
<p>这部分不明白的地方比较多。。。。。。。。。。。。。。。。。。。。。写的几乎是逐字稿了。。。。</p>
</blockquote>
<ul>
<li>
<p><strong>可视化权重</strong></p>
<p>如果对中间的卷积层做相同的可视化，会发现对应图像的<strong>可解释性会差很多</strong>， 第二层的权重会经过 <code>ReLU</code> 激活函数或其他的非线性激活函数，接收了 16 个通道的输入，并且使用 20 个卷积核进行 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>7</mn><mo>×</mo><mn>7</mn></mrow><annotation encoding="application/x-tex">7\times7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">7</span></span></span></span> 的卷积，我们不能直接将这些权重进行可视化，因为输入图像的深度是 16 维的，且每个卷积核的尺寸为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>16</mn><mo>×</mo><mn>7</mn><mo>×</mo><mn>7</mn></mrow><annotation encoding="application/x-tex">16\times7\times7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">16</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">7</span></span></span></span> ，共有 20 个卷积核。这里的做法是：对于单一的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>16</mn><mo>×</mo><mn>7</mn><mo>×</mo><mn>7</mn></mrow><annotation encoding="application/x-tex">16\times7\times7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">16</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">7</span></span></span></span> 的卷积核，画出 1 6个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>7</mn><mo>×</mo><mn>7</mn></mrow><annotation encoding="application/x-tex">7\times7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">7</span></span></span></span>的灰度图，一共画20组，下图的灰度图像显示了第二层某个卷积核的权重，因为有 20 个输出，所以第二层卷积层有 20 个形状为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>16</mn><mo>×</mo><mn>7</mn><mo>×</mo><mn>7</mn></mrow><annotation encoding="application/x-tex">16\times7\times7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">16</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">7</span></span></span></span> 的卷积核。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/12/150413-757ba.png" alt=""></p>
<p>将卷积核权重进行可视化后，可以发现他们具有一些空间结构，但并不能直接观察到很有价值的信息，因为这些卷积核并<strong>没有直接连接到输入图像</strong>，所以我们需要想出一些更奇特的方法，用来理解中间卷积层究竟在做什么。</p>
</li>
<li>
<p><strong>可视化激活图（feature map）</strong></p>
<p>中间层<strong>可视化权重</strong>的解释性并不是很强，而可视化中间层的 <strong>feature map</strong> 在某些情况下更具可解释性。再次以 AlexNet 为例，AlexNet 的第 5 个卷积层提供了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>128</mn><mo>×</mo><mn>13</mn><mo>×</mo><mn>13</mn></mrow><annotation encoding="application/x-tex">128\times13\times13</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">128</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">13</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">13</span></span></span></span> 的张量，我们可以将其转化为 128 个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>13</mn><mo>×</mo><mn>13</mn></mrow><annotation encoding="application/x-tex">13\times13</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">13</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">13</span></span></span></span>  的灰度图像，这能让我们意识到 CNN 需要寻找的特征在输入中是什么样的，下面是可视化的一个具体例子：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/12/204010-1900b.png" alt=""></p>
<p>可以看到中间高亮的图像，似乎在匹配输入的图像，寻找类似于人脸的东西，但其他的大部分图像都是噪声。</p>
</li>
<li>
<h5 id="最大激活块（Maximally-Activating-Patches）">最大激活块（Maximally Activating Patches）</h5>
<p>对于可视化中间层可以做的另一件事情是：可视化输入图像中不同类型的图像块，可以最大程度地激活不同的特征、不同的神经元。比如选取 AlexNet 的第 5 个卷积层的第 17 个激活图（共 128 个），随后输入很多图像通过卷积神经网络，分别记录 Conv5 第 17 个激活图的值，这个特征图上部分值会被输入图片集<strong>最大激活</strong>，由于每个神经元的感受野有限，我们可以画出<strong>这些被最大激活的神经元对应在原始输入图片的小块</strong>，通过这些小块观察不同的神经元在寻找哪些信息。下面是一些来自特定神经元输入图像块的例子：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/12/210305-cbafd.png" alt=""></p>
<p>其中，每一行都是某个神经元被最大激活对应的图片块，可以看到有的神经元在寻找类似眼睛的东西，有的在寻找弯曲的曲线等。如果不使用Conv5的激活图，而是更后面的卷积层，由于<strong>卷积核视野扩大</strong>，寻找的特征也会更加复杂，比如人脸、相机等，对应下图的下面部分。</p>
<blockquote>
<p>一个单层的卷积核对应一行，多个就形成了上图，意味着这层卷积核关注的是原图的什么（可能是眼睛、脸）</p>
</blockquote>
</li>
</ul>
<h3 id="2-3-CNN-最后层">2.3 CNN 最后层</h3>
<p>现在来讨论模型的最后一层，CNN 的最后一层可能会得到 1000 个类的得分情况，来告知数据集中每个类的得分，在最后一层之前一般会存在全连接层，AlexNet 用 4096 维的特征向量来表示图像，然后将其输入到最后一层，来预测最终类的得分。</p>
<p>另一种用于可视化和理解 CNN 的方法是<strong>尝试理解神经网络的最后一层</strong>，可以通过 CNN 来检测一些图像，并为每一幅图像<strong>标记对应的 4096 维向量</strong>，试着可视化最后一层隐层。</p>
<ul>
<li>
<p>最近邻</p>
<p>我们可能会看到尝试使用<strong>最近邻法</strong>，最近邻法可以在像素空间中寻找 “近邻”，比如之前在 <code>CIFAR-10</code> 数据集上使用 NN 法，会发现找的到图像和查询的图像看起来非常相似，但不一定是一类事物。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/12/153807-04d12.png" alt=""></p>
<p><strong>与其根据像素空间来计算近邻，不如在由卷积得到的 4096 维的特征空间中计算近邻</strong>，如下图所示，有些图像在像素空间中并不类似（比如大象的第一张和第四张），但由于是在由 CNN 计算得到的 4096 维特征空间上进行 NN 计算，最终会认为两张图象直接非常相似。</p>
<blockquote>
<p>大概意思就是，比起在原始像素上使用 NN，不如在卷积得到的向量上使用 NN，说明了 4096 维的特征空间能捕捉到图像中的语义内容。</p>
</blockquote>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/12/153349-b0d2f.png" alt=""></p>
</li>
<li>
<p><strong>降维</strong></p>
<p>另一种用于观察 CNN 最后一层的方法是<strong>降维</strong>，<strong>通过 PCA 将 4096 维的特征向量压缩到二维空间</strong>，以便更加直观的可视化特征空间。除了 PCA ，还有一种更强大的降维算法 —— <code>t-SNE</code> ，也就是 <code>t-distributed Stochastic Neighbor Embeddings</code> 的缩写，它是以一种在深度学习领域常被使用的，<strong>用于可视化特征的非线性降维方法</strong>。下图是 <code>t-SNE</code> 的一个应用实例，展示了在 <code>mnist</code> 数据集上的降维。</p>
<blockquote>
<p><code>mnist</code> 也就是手写数字数据集（0 - 9）</p>
</blockquote>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/12/155155-369b5.png" alt=""></p>
<p>可以看到降维后的数据集可以更清晰的展现出集群的特点，这些集群对应了 <code>mnist</code> 数据集中的数据。</p>
<p>所以我们现在就可以做类似的可视化工作，也就是在图像分类器网络的最后一层上应用 <code>t-SNE</code> 降维。具体来说就是提取大量图像，并让他们在 CNN 上运行，记录每个图像在网络最后一层产生的 4096 维特征向量（数量很大），通过 <code>t-SNE</code> 把 4096 维的特征空间压缩至 2 维，随后在 2 维的特征空间中布局网格，并观察 2 维特征空间网格每个位置会出现什么类型的图像。通过这种做法可以粗略地感受到学习到的特征空间的几何结构。</p>
<ul>
<li>
<p>粗略版本</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/12/160330-cc87d.png" alt=""></p>
<p>通过粗略版本可以观察到，左下角都是一些绿色的东西，而右上角偏蓝。</p>
</li>
<li>
<p>高清版本</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/12/160244-37ef8.jpeg" alt=""></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cs.stanford.edu/people/karpathy/cnnembed/cnn_embed_full_4k.jpg" alt="img"></p>
</li>
</ul>
</li>
</ul>
<h2 id="三、-理解像素">三、 理解像素</h2>
<h3 id="3-1-遮挡实验">3.1 遮挡实验</h3>
<p>遮挡实验是为了弄清楚<strong>究竟是输入图像的哪部分导致神经网络做出了最终的分类决策</strong>。以包含了一头大象的图片为例，实验的具体方法是遮挡住图像的某个部分（替换为数据集的平均像素值），然后将图像输入网络，记录遮挡图像的预测概率。随后将此遮挡块滑过所有位置，重复所有步骤，最后绘制图像的热力图，如下图所示。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/12/214937-8a968.png" alt=""></p>
<p>热力图显示了在该位置设定遮挡块时，对应的预测概率为多少。如果遮挡了图像的某部分，导致神经网络分值急剧变化，那么该遮挡区域可能对模型分类决策起到非常重要的作用。</p>
<blockquote>
<p>图中颜色越深的地方代表预测概率越低，以大象为例，如果遮住大象的脸部，预测概率会急剧下降，说明大象的脸部像素对神经网络做出决策有很重要的作用。</p>
</blockquote>
<h3 id="3-2-显著图">3.2 显著图</h3>
<p>给出一只狗的输入图像，以及狗的预测类标签，我们想知道输入图像中的哪部分像素对于分类是最重要的，除了遮挡实验，显著图是从另一个角度解决这个问题的方法，具体做法是：计算分类得分相对于图像像素的梯度，这将告诉我们，在一阶近似意义上对于输入图片的每个像素<strong>进行小小的扰动</strong>，那么相应分类的分值会有多大的变化。当通过显著图的方法运行小狗的图像，能很方便地看出图中小狗的轮廓，这表示网络正在寻找的特征可能在这些像素之间。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/13/140108-1b3be.png" alt=""></p>
<p>如果对不同的图像做相同地操作，就能发现神经网络在寻找合适的区域。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/13/140159-0385b.png" alt=""></p>
<blockquote>
<p>进行语义分割的时候也可以运用显著图的方法，可以<strong>在没有任何标签的情况下</strong>可以运用显著图进行语义分割。</p>
</blockquote>
<h3 id="3-3引导式反向传播-（guided-backprop）">3.3引导式反向传播 （guided backprop）</h3>
<p>显著图是使用<strong>分类得分</strong>对图片上的<strong>像素</strong>求导得出对分类决策影响较大的像素，而引导式反向传播是使用 CNN <strong>某一层的特定神经元的值</strong>对像素求导，这样就能观察<strong>图像的像素</strong>对<strong>特定神经元</strong>的影响。但是这里的反向传播是<strong>引导式的</strong>，即 <code>ReLU</code> 函数反向传播时，只回传大于0的梯度，如下图所示。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/13/141238-cd1b0.png" alt=""></p>
<blockquote>
<p>虽然这样做很奇怪，但是效果很好，图像很清晰。</p>
</blockquote>
<p>当使用引导式反向传播，而不是用定期反向传播时，更容易获得更清晰的图像，来告知图像中的哪部分像素影响了特定的神经元。</p>
<p>我们把<strong>引导式反向传播计算的梯度</strong>可视化和<strong>最大激活块</strong>进行对比，发现这两者的表现很相似。下图左边是最大激活块，每一行代表一个神经元，右侧是该神经元计算得到的对原始像素的引导式反向传播梯度。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/13/141905-d573a.png" alt="image-20220713141905105"></p>
<p>以第一行为例，最大激活该神经元的图像块都是一些<strong>圆形的区域</strong>，这表明该神经元可能在寻找圆形状物体，然后观察右边，发现<strong>的确是圆形区域的像素</strong>会影响的神经元的值。</p>
<h3 id="3-4-梯度上升（-Gradient-Ascent）">3.4 梯度上升（ Gradient Ascent）</h3>
<p>从以上讲述的几个方法中，我们了解到如何查看<strong>对神经元影响最大的像素</strong>，如果我们在一些输入图像中移除这种依赖性，那什么类型的输入才会激活该神经元？我们可以通过<strong>梯度上升</strong>算法来解决这个问题。</p>
<p>我们总在训练神经网络时使用梯度下降来使 loss 最小化，而现在我们想要在图像上执行梯度上升，来合成图像，以尝试<strong>最大化</strong>某些<strong>中间神经元</strong>和<strong>类别</strong>的分值，来改变像素值。在执行梯度上升的过程中，我们不再优化权重，而是让权重保持不变，尝试改变一些图像的像素，使该<strong>神经元的值</strong>或对应<strong>类的分值最大化</strong>。除此之外，我们还需要用到正则项，以阻止生成的图像过拟合，而生成很奇怪的东西。</p>
<p>生成图像具备两个属性：</p>
<ol>
<li>使最大程度地激活分类得分或神经元的值；</li>
<li>使我们希望这个生成的图像看起来是自然的（正则项强制生成的图像看起来是自然的图像）。</li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/13/144447-ab485.png" alt=""></p>
<p>具体方法是：把初始图象初始化为 0 或者添加高斯噪声，然后通过神经网络<strong>重复传入图像</strong>并计算 1. 神经元分值，2. 反向传播计算神经元分值对图像像素的梯度，3. 更新图像以使神经元分值最大化。不断重复上述步骤直到图像可以理解为止。</p>
<p>上面讨论到为<strong>图像进行正则化</strong>，一个比较常见的正则化方法是通过 <code>L2</code> 正则化来约束像素，针对分类得分生成的图片如下所示：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/13/145834-28024.png" alt=""></p>
<p>用肉眼很难看清楚，但是能看出个大概。</p>
<p>除了 <code>L2</code> 正则化外，还能使用一些方法来优化正则，比如对生成的图像进行<strong>高斯模糊处理</strong>、将<strong>像素值特别小或梯度值特别小的值去掉</strong>。这些方法会使生成的图像更清晰。也可以针对某个神经元进行梯度上升。层数越高，生成的结构越复杂，如下图所示。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/13/150704-0723d.png" alt=""></p>
<blockquote>
<p>添加多模态（multi-faceted）可视化可以提供更好的结果(加上更仔细的正则化，中心偏差）。通过优化 FC6 的特征而不是原始像素，会得到更加自然的图像。</p>
</blockquote>
<p>通过图像像素的梯度来合成图像的想法其实非常强大，其中一个有趣的想法就是<strong>愚弄网络</strong>，即选取一些任意的图像，然后告诉网络我们希望最大化另一类事物的分值，然后修改原图的像素，最后网络会将该图像分类成零一类事物，而图像看上去却没多大变化</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/13/152036-e84e1.png" alt=""></p>
<h2 id="四、DeepDream">四、DeepDream</h2>
<p>我们可以做的另一件<strong>基于梯度的图像优化</strong>是 <code>DeepDream</code>，这谷歌发布的一篇博客文章的内容。仍然利用<strong>梯度上升</strong>的原理，不再是通过最大化神经元激活来合成图片，而是<strong>直接放大某些层的神经元激活特征</strong>。</p>
<p>想法是输入图像，通过神经网络运行到某一层，接着进行反向传播，并<strong>设置该层的梯度等于激活值</strong>，然后反向传播到图像，并不断地更新图像。</p>
<p>上述步骤试图<strong>放大神经网络在图像中检测到的特征</strong>，无论那层存在什么特征，都将其梯度设为特征值，<strong>使神经网络放大它在图像中检测到的特征</strong>，这种方法同样可以用于最大化图像在该层中的 <code>L2</code> 范数。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/13/154804-14a33.png" alt=""></p>
<p>做完一切后，输入一张天空的图像，可以把网络中学到的特征在原图像上生成：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/13/155849-c513c.png" alt="image-20220713155848896"></p>
<p>现在特征已经被放置在了天空的图像上，通过这个过程，特征得到了放大，可以看到很多“突变物体”。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/13/160143-45334.png" alt=""></p>
<p>对神经网络不同层做同样的操作也会得到差不多的结果，下图选择的是神经网络一个较低层，似乎正在计算边缘或者漩涡之类的东西。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/13/160400-86378.png" alt=""></p>
<p>如果长时间运行 DeepDream ，并且进行多尺度处理，可能得到很 “诡异” 的图像：<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/13/160454-ca19e.png" alt="image-20220713160454373"></p>
<p>下面是在 MIT Places Dataset 上运行 DeepDream 后的结果（MIT 数据集包含了 200 种不同的场景图像）：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/13/160659-7c59a.png" alt=""></p>
<h2 id="五、风格迁移">五、风格迁移</h2>
<h3 id="5-1-特征反演（Feature-Inversion）">5.1 特征反演（Feature Inversion）</h3>
<p>特征反演是为了查看<strong>不同层的特征向量能保留多少原始的图片信息</strong>。</p>
<p>具体过程是：向 CNN  种喂入一张图像，选取其在 CNN 某一层产生的特征向量，随后根据该特征向量重构图像，重构后的图像会提供一些<strong>神经网络捕获到的图像类型信息</strong>（可以通过梯度上升和正则化做到）。</p>
<blockquote>
<p>与其最大化某些分值，不如最小化特征向量之间的距离，并且在生成图像的特征之间尝试合成一个新的相匹配的图像。</p>
</blockquote>
<p>全变差正则化将左右相邻像素之间的差异拼凑成上下相邻，尝试增加生成图像中特殊的平滑度。</p>
<p>用这种方法，我们可以看到不同层的特征向量所包含的信息完整度：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/13/163127-62307.png" alt=""></p>
<p>最左侧是原始图像，右侧是根据 <code>VGG-16</code> 不同层记录的特征生成的图像，这能让我们了解到这张图像在神经网络不同层的信息存储量。</p>
<p>在relu2_2层，可以根据特征向量几乎无损地恢复出原图片；但是尝试从ReLU4_3 ReLU5_1重构图像时，可以看到图像的<strong>一般空间结构</strong>被保留了下来，仍可以分辨出大象，苹果和香蕉。但是许多低<strong>层次的细节</strong>并比如纹理、颜色在神经网路的较高层<strong>更容易损失</strong>。</p>
<h3 id="5-2-纹理生成">5.2 纹理生成</h3>
<p>纹理合成在计算机图形学里是一个老问题，比如给定一些纹理的输入图像，想要生成更大块的相同纹理的图像，如下图所示。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/13/163654-aef2e.png" alt=""></p>
<p>NN 算法在纹理生成问题的表现非常好，但是没有神经网络，这里采用的是非常简单的方法，即按照扫描线一次一个像素地遍历生成图像，然后<strong>根据已经生成的像素查看当前像素周围的邻域，并在输入图像地图像块中计算近邻，然后从输入图像中复制像素</strong>。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/13/164340-746a6.png" alt=""></p>
<p>如果使用的是复杂纹理，直接从输入图像的图像块复制像素的方法可能会行不通。 有一篇论文试图<strong>将神经网络的特征应用到纹理合成问题上</strong>，最终将这个问题转化为梯度上升的过程，类似于 feature map，其中各种各样的 feature 指的是物体上的特征。</p>
<ul>
<li>
<p><strong>格莱姆矩阵</strong>（Gram Matrix）</p>
<p>为了在神经网络上进行纹理合成，使用了格莱姆矩阵 。将输入图像传递给 CNN ，抽取他们在某层的卷积特征，假设卷积特征大小为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>×</mo><mi>H</mi><mo>×</mo><mi>W</mi></mrow><annotation encoding="application/x-tex">C\times H\times W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span> ，可以将其看作是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo>×</mo><mi>W</mi></mrow><annotation encoding="application/x-tex">H\times W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span>  个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span> 维的特征向量，用于描述图像在这点的外观，做矩阵乘法可以得到一个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>×</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">C\times C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span> 的矩阵。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/13/170350-30b25.png" alt=""></p>
<p>然后对激活图中任意两个C维向量的组合，都可以求出这样一个矩阵。把这些矩阵求和并平均，就是格莱姆矩阵。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/13/170423-2182e.png" alt=""></p>
<p>格莱姆矩阵告诉我们<strong>两个点代表的不同特征的同现关系</strong>，矩阵中位置索引为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mi>j</mi></mrow><annotation encoding="application/x-tex">ij</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">ij</span></span></span></span> 的元素值非常大，这意味着这两个输入向量的位置索引为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span> 的元素值非常大。这以某种方式捕获了一些二阶统计量，即映射特征图中的<strong>哪些特征倾向于在空间的不同位置一起激活</strong>。</p>
<blockquote>
<p>Q：为什么不使用协方差矩阵或类似的方法，而是使用格莱姆矩阵？</p>
<p>A：格莱姆矩阵其实是 feature 之间的<strong>偏心协方差矩阵</strong>（即没有减去均值的协方差矩阵）。其计算了每个通道特征之间的相关性，考察哪些特征是此消彼长的，哪些特征是同时出现的。</p>
<p>我们认为格莱姆矩阵度量了图片中的纹理特性，并且不包含图像的结构信息，因为我们对图像中的每一点所对应的特征向量取平均值，它只是捕获特征间的二阶同现统计量，这最终是一个很好的纹理描述符。</p>
<p>事实上，使用协方差矩阵代替格莱姆矩阵也能取得很好的效果，但是格莱姆矩阵有更高效的计算方法：将激活图张量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>×</mo><mi>H</mi><mo>×</mo><mi>W</mi></mrow><annotation encoding="application/x-tex">C\times H\times W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span>展开成 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>×</mo><mi>H</mi><mi>W</mi></mrow><annotation encoding="application/x-tex">C\times HW</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span>的形式，然后将其乘以其转置，即得到gram矩阵。</p>
</blockquote>
</li>
<li>
<h5 id="神经纹理生成（Neural-Texture-Synthesis）">神经纹理生成（Neural Texture Synthesis）</h5>
<p>当我们有了格莱姆矩阵这一度量图像纹理特性的工具后，就可以使用类似于梯度上升算法来产生特定纹理的图像。算法流程为：</p>
<ol>
<li>使用 ImageNet 数据集<strong>预训练</strong>一个 VGG 网络</li>
<li>把含有纹理的图像输入到VGG网络，进行前向传播，<strong>记录其每一层的激活图</strong></li>
<li>计算每一层的格<strong>莱姆矩阵</strong>，给出特征的外积**</li>
<li>在随机噪声中<strong>初始化</strong>生成图像</li>
<li>通过 CNN <strong>生成图像</strong>，计算每一层的格拉姆矩阵</li>
<li><strong>计算损失</strong>:  格莱姆矩阵之间 L2 距离的加权和</li>
<li>反向传播得到图片的梯度</li>
<li>根据<strong>梯度上升</strong>一点点更新图像的像素</li>
<li>重复步骤 5</li>
</ol>
<p>最终会生成与纹理图像相匹配的纹理图像。效果如下：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/13/174323-7e6f5.png" alt=""></p>
<p>上图说明，如果以<strong>更高层格莱姆矩阵</strong>的 <code>L2</code> 距离作为损失函数，那么生成图像就会更好地重建图像的纹理结构。这是由于<strong>更高层的神经元具有更大的感受野</strong>导致的。</p>
</li>
</ul>
<h3 id="5-3-风格迁移（Style-Transfer）">5.3 风格迁移（Style Transfer）</h3>
<p>结合<strong>特征反演</strong>和<strong>纹理生成</strong>，就可以实现所谓的<strong>风格迁移</strong>。</p>
<p>在风格迁移中，我们把两张图像作为输入图像，第一步将其中一张图像做为<strong>内容图像</strong>，他将引导生成<strong>图像的主体</strong>；将零一幅图像作为<strong>风格图像</strong>，负责生成图像的<strong>纹理或风格</strong>，然后<strong>共同做特征识别，最小化内容图像的特征重构损失，以及风格图像的格莱姆矩阵损失</strong>。完成以上步骤，就能获得非常不错的图像：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/13/175044-876f3.png" alt=""></p>
<p>基本架构如下：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/13/175440-cfb28.png" alt=""></p>
<p>在这个框架中，使用<strong>随机噪声初始化</strong>生成图像，同时优化<strong>特征反演</strong>和<strong>纹理生成</strong>的<strong>损失函数</strong>（生成图像与内容图像激活特征向量的 <code>L2</code> 距离以及与风格图像格莱姆矩阵的 <code>L2</code> 距离的加权和），计算图像上的<strong>像素梯度</strong>，重复这些步骤，在生成图像上执行<strong>梯度上升</strong>。经过一些迭代后会生成风格迁移后的图像。这样生成图像既具有内容图像的空间结构，又具有风格图像的纹理结构。</p>
<p>由于网络使用的<strong>总损失</strong>是<strong>特征反演</strong>和<strong>纹理生成</strong>的两部分损失的<strong>加权和</strong>，所以<strong>调整这个加权值</strong>可以得到不同风格的输出：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/13/175729-7311d.png" alt=""></p>
<p>也可以改变风格图像的尺寸：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/13/175809-20b58.png" alt="image-20220713175809098"></p>
<p>此外，也可以使用<strong>不同风格的格莱姆矩阵</strong>的加权和，来生成多风格图：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/13/175840-a482e.png" alt=""></p>
<p>实现代码：<a target="_blank" rel="noopener" href="https://github.com/jcjohnson/neural-style">点击这里</a></p>
<h3 id="5-4-快速风格迁移（Fast-style-Transfer）">5.4 快速风格迁移（Fast style Transfer）</h3>
<p>但是风格迁移算法有一个问题：<strong>算法的效率特别低</strong>。为了生成新图像，需要在预训练网络中计算很多前向传播和反向传播，特别是为了生成高分辨率的图像，每个 4K 图像的前向传播和反向传播都需要大量的计算和内存。</p>
<p>解决方法是训练另一种神经网络，来进行风格迁移的工作。</p>
<p>有一篇研究提出了这么一个想法：在一开始就<strong>训练好想要迁移的风格</strong>，并不是为每个图象运行一个单独的优化程序，而是训练一个可以输入内容图像的前馈网络，直接输出风格迁移后的结果。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2022/07/13/181137-a80cf.png" alt=""></p>
<p>训练前馈神将网络的方法是：在训练期间计算相同内容图像和风格图像的损失，然后使用<strong>相同梯度</strong>来更新前馈神经网络的权重，一旦训练完成，只需在训练好的网络上进行单一的前向传播。训练过程可能需要耗费几个小时的时间，但是一旦训练完成，生成风格迁移图像的速度会很快。</p>
<p>实现代码：<a target="_blank" rel="noopener" href="https://github.com/jcjohnson/fast-neural-style">点击这里</a></p>
<h2 id="总结">总结</h2>
<ol>
<li><strong>理解CNN：</strong>
<ul>
<li>激活值：在激活值的基础上理解这些神经元在<strong>寻找什么特征</strong>，方法有最邻近、降维、最大化图像块、遮挡；</li>
<li>梯度：使用<strong>梯度上升</strong>合成新图像来 理解特征的意义，比如显著图、类可视化、愚弄图像、特征反演。</li>
</ul>
</li>
<li>**风格迁移：**特征反演 + 纹理生成。</li>
</ol>
</article><div class="post-copyright"><div class="copyright-cc-box"><i class="anzhiyufont anzhiyu-icon-copyright"></i></div><div class="post-copyright__author_box"><a class="post-copyright__author_img" href="/" title="头像"><img class="post-copyright__author_img_back" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne.gitee.io/kuhne.gitee.io/img/head.jpg" title="头像" alt="头像"><img class="post-copyright__author_img_front" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne.gitee.io/kuhne.gitee.io/img/head.jpg" title="头像" alt="头像"></a><div class="post-copyright__author_name">Kuhne</div><div class="post-copyright__author_desc">间接性内卷 持续性摆烂</div></div><div class="post-copyright__post__info"><a class="post-copyright__original" title="该文章为原创文章，注意版权协议" href="https://kuhne.gitee.io/kuhne.gitee.io/posts/1af2ae7a.html">原创</a><a class="post-copyright-title"><span onclick="rm.copyPageUrl('https://kuhne.gitee.io/kuhne.gitee.io/posts/1af2ae7a.html')">cs231n 学习笔记（11）可视化与理解</span></a></div><div class="post-tools" id="post-tools"><div class="post-tools-left"><div class="rewardLeftButton"><div class="post-reward" onclick="anzhiyu.addRewardMask()"><div class="reward-button button--animated" title="赞赏作者"><i class="anzhiyufont anzhiyu-icon-hand-heart-fill"></i>打赏作者</div><div class="reward-main"><div class="reward-all"><span class="reward-title">感谢你赐予我前进的力量</span><ul class="reward-group"><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul><a class="reward-main-btn" href="/about/#about-reward" target="_blank"><div class="reward-text">赞赏者名单</div><div class="reward-dec">因为你们的支持让我意识到写文章的价值🙏</div></a></div></div></div><div id="quit-box" onclick="anzhiyu.removeRewardMask()" style="display: none"></div></div><div class="shareRight"><div class="share-link mobile"><div class="share-qrcode"><div class="share-button" title="使用手机访问这篇文章"><i class="anzhiyufont anzhiyu-icon-qrcode"></i></div><div class="share-main"><div class="share-main-all"><div id="qrcode" title="https://kuhne.gitee.io/kuhne.gitee.io/posts/1af2ae7a.html"></div><div class="reward-dec">使用手机访问这篇文章</div></div></div></div></div><div class="share-link weibo"><a class="share-button" target="_blank" href="https://service.weibo.com/share/share.php?title=cs231n 学习笔记（11）可视化与理解&amp;url=https://kuhne.gitee.io/kuhne.gitee.io/posts/1af2ae7a.html&amp;pic=https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/img/2901e2f51d643b321c61e158805fe248.jpeg" rel="external nofollow noreferrer noopener"><i class="anzhiyufont anzhiyu-icon-weibo"></i></a></div><div class="share-link copyurl"><div class="share-button" id="post-share-url" title="复制链接" onclick="rm.copyPageUrl()"><i class="anzhiyufont anzhiyu-icon-link"></i></div></div></div></div></div><div class="post-copyright__notice"><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://kuhne.gitee.io/kuhne.gitee.io" target="_blank">Kuhne</a>！</span></div></div><div class="post-tools-right"><div class="tag_share"><div class="post-meta__box"><div class="post-meta__box__tag-list"><a class="post-meta__box__tags" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>计算机视觉<span class="tagsPageCount">12</span></a><a class="post-meta__box__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>深度学习<span class="tagsPageCount">15</span></a></div></div></div><div class="post_share"><div class="social-share" data-image="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2023/09/07/20230907192257-a360e8.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"/><script src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer="defer"></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/1819e07.html"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/img/2901e2f51d643b321c61e158805fe248.jpeg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">cs231n 学习笔记（10）目标检测与图像分割</div></div></a></div><div class="next-post pull-right"><a href="/posts/4a818336.html"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/img/2901e2f51d643b321c61e158805fe248.jpeg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">cs231n 学习笔记（12）生成模型</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="anzhiyufont anzhiyu-icon-thumbs-up fa-fw" style="font-size: 1.5rem; margin-right: 4px"></i><span>喜欢这篇文章的人也看了</span></div><div class="relatedPosts-list"><div><a href="/posts/4a818336.html" title="cs231n 学习笔记（12）生成模型"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/img/2901e2f51d643b321c61e158805fe248.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2022-07-24</div><div class="title">cs231n 学习笔记（12）生成模型</div></div></a></div><div><a href="/posts/1819e07.html" title="cs231n 学习笔记（10）目标检测与图像分割"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/img/2901e2f51d643b321c61e158805fe248.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2022-07-15</div><div class="title">cs231n 学习笔记（10）目标检测与图像分割</div></div></a></div><div><a href="/posts/3fc42b2c.html" title="cs231n 学习笔记（9）循环神经网络"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/img/2901e2f51d643b321c61e158805fe248.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2022-07-10</div><div class="title">cs231n 学习笔记（9）循环神经网络</div></div></a></div><div><a href="/posts/dc7d8d44.html" title="cs231n 学习笔记（8）经典的 CNN 架构"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/img/2901e2f51d643b321c61e158805fe248.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2022-07-03</div><div class="title">cs231n 学习笔记（8）经典的 CNN 架构</div></div></a></div><div><a href="/posts/90deef5.html" title="cs231n 学习笔记（7）深度学习软件"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/img/2901e2f51d643b321c61e158805fe248.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2022-06-26</div><div class="title">cs231n 学习笔记（7）深度学习软件</div></div></a></div><div><a href="/posts/39060a00.html" title="cs231n 学习笔记（6）训练神经网络（二）"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/img/2901e2f51d643b321c61e158805fe248.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2022-06-22</div><div class="title">cs231n 学习笔记（6）训练神经网络（二）</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="anzhiyufont anzhiyu-icon-comments"></i><span> 评论</span></div><div class="comment-randomInfo"><a onclick="anzhiyu.addRandomCommentInfo()" href="javascript:void(0)">匿名评论</a><a href="/privacy" style="margin-left: 4px">隐私政策</a></div><div class="comment-tips" id="comment-tips"><span>✅ 你无需删除空行，直接评论以获取最佳展示效果</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div><div class="comment-barrage"></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-content"><div class="author-info__sayhi" id="author-info__sayhi" onclick="anzhiyu.changeSayHelloText()"></div><div class="author-info-avatar"><img class="avatar-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne.gitee.io/kuhne.gitee.io/img/head.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-status"><img class="g-status" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://emotion.acs.pw/emotion/bilibili_hotKey/危.jpg" ait="status"/></div></div><div class="author-info__description"><div style="line-height:1.38;margin:0.6rem 0;text-align:justify;color:rgba(255, 255, 255, 0.8);">一个菜鸟的垃圾加工厂。</div><div style="line-height:1.38;margin:0.6rem 0;text-align:justify;color:rgba(255, 255, 255, 0.8);">希望你你可以在这里找到对你有用的<b style="color:#fff">有用</b>的<b style="color:#fff">垃圾</b>。</div></div><div class="author-info__bottom-group"><a class="author-info__bottom-group-left" href="/"><h1 class="author-info__name">Kuhne</h1><div class="author-info__desc">间接性内卷 持续性摆烂</div></a><div class="card-info-social-icons is-center"><a class="social-icon faa-parent animated-hover" href="https://github.com/" target="_blank" title="Github"><i class="anzhiyufont anzhiyu-icon-github"></i></a><a class="social-icon faa-parent animated-hover" href="https://space.bilibili.com/" target="_blank" title="BiliBili"><i class="anzhiyufont anzhiyu-icon-bilibili"></i></a></div></div></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bullhorn anzhiyu-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来看我的博客~</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bars"></i><span>文章目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">cs231n 学习笔记（11）可视化与理解</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E9%97%AE%E9%A2%98%E6%8F%8F%E8%BF%B0"><span class="toc-number">1.1.</span> <span class="toc-text">一、问题描述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E7%90%86%E8%A7%A3%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">1.2.</span> <span class="toc-text">二、理解卷积神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-CNN-%E7%AC%AC%E4%B8%80%E5%B1%82"><span class="toc-number">1.2.1.</span> <span class="toc-text">2.1 CNN 第一层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-CNN-%E4%B8%AD%E9%97%B4%E5%B1%82"><span class="toc-number">1.2.2.</span> <span class="toc-text">2.2 CNN 中间层</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%9C%80%E5%A4%A7%E6%BF%80%E6%B4%BB%E5%9D%97%EF%BC%88Maximally-Activating-Patches%EF%BC%89"><span class="toc-number">1.2.2.0.1.</span> <span class="toc-text">最大激活块（Maximally Activating Patches）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-CNN-%E6%9C%80%E5%90%8E%E5%B1%82"><span class="toc-number">1.2.3.</span> <span class="toc-text">2.3 CNN 最后层</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81-%E7%90%86%E8%A7%A3%E5%83%8F%E7%B4%A0"><span class="toc-number">1.3.</span> <span class="toc-text">三、 理解像素</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E9%81%AE%E6%8C%A1%E5%AE%9E%E9%AA%8C"><span class="toc-number">1.3.1.</span> <span class="toc-text">3.1 遮挡实验</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E6%98%BE%E8%91%97%E5%9B%BE"><span class="toc-number">1.3.2.</span> <span class="toc-text">3.2 显著图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3%E5%BC%95%E5%AF%BC%E5%BC%8F%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD-%EF%BC%88guided-backprop%EF%BC%89"><span class="toc-number">1.3.3.</span> <span class="toc-text">3.3引导式反向传播 （guided backprop）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-%E6%A2%AF%E5%BA%A6%E4%B8%8A%E5%8D%87%EF%BC%88-Gradient-Ascent%EF%BC%89"><span class="toc-number">1.3.4.</span> <span class="toc-text">3.4 梯度上升（ Gradient Ascent）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81DeepDream"><span class="toc-number">1.4.</span> <span class="toc-text">四、DeepDream</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB"><span class="toc-number">1.5.</span> <span class="toc-text">五、风格迁移</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E7%89%B9%E5%BE%81%E5%8F%8D%E6%BC%94%EF%BC%88Feature-Inversion%EF%BC%89"><span class="toc-number">1.5.1.</span> <span class="toc-text">5.1 特征反演（Feature Inversion）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E7%BA%B9%E7%90%86%E7%94%9F%E6%88%90"><span class="toc-number">1.5.2.</span> <span class="toc-text">5.2 纹理生成</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E7%BA%B9%E7%90%86%E7%94%9F%E6%88%90%EF%BC%88Neural-Texture-Synthesis%EF%BC%89"><span class="toc-number">1.5.2.0.1.</span> <span class="toc-text">神经纹理生成（Neural Texture Synthesis）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB%EF%BC%88Style-Transfer%EF%BC%89"><span class="toc-number">1.5.3.</span> <span class="toc-text">5.3 风格迁移（Style Transfer）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-%E5%BF%AB%E9%80%9F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB%EF%BC%88Fast-style-Transfer%EF%BC%89"><span class="toc-number">1.5.4.</span> <span class="toc-text">5.4 快速风格迁移（Fast style Transfer）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">1.6.</span> <span class="toc-text">总结</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-history"></i><span>最近发布</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/45e85deb.html" title="Nginx 基本使用"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2023/09/07/20230907192257-a360e8.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Nginx 基本使用"/></a><div class="content"><a class="title" href="/posts/45e85deb.html" title="Nginx 基本使用">Nginx 基本使用</a><time datetime="2023-09-07T11:19:06.000Z" title="发表于 2023-09-07 19:19:06">2023-09-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/8d037627.html" title="Git 及 GitHub 常用命令记录"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2023/02/27/20230227141226-160f64.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Git 及 GitHub 常用命令记录"/></a><div class="content"><a class="title" href="/posts/8d037627.html" title="Git 及 GitHub 常用命令记录">Git 及 GitHub 常用命令记录</a><time datetime="2023-02-27T06:08:31.000Z" title="发表于 2023-02-27 14:08:31">2023-02-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/a6d8a9c3.html" title="个人常用 Linux 命令"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2023/02/26/20230226105141-94929b.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="个人常用 Linux 命令"/></a><div class="content"><a class="title" href="/posts/a6d8a9c3.html" title="个人常用 Linux 命令">个人常用 Linux 命令</a><time datetime="2023-02-26T02:47:48.000Z" title="发表于 2023-02-26 10:47:48">2023-02-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/3b91aa4a.html" title="Linux 服务器环境配置"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/img/4c417afa91736428def17dcc96aa64b8.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Linux 服务器环境配置"/></a><div class="content"><a class="title" href="/posts/3b91aa4a.html" title="Linux 服务器环境配置">Linux 服务器环境配置</a><time datetime="2022-09-14T08:01:29.000Z" title="发表于 2022-09-14 16:01:29">2022-09-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/165b6b1f.html" title="论文整理（3）Measuring Compositional Consistency for Video Question Answering"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/img/top2.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="论文整理（3）Measuring Compositional Consistency for Video Question Answering"/></a><div class="content"><a class="title" href="/posts/165b6b1f.html" title="论文整理（3）Measuring Compositional Consistency for Video Question Answering">论文整理（3）Measuring Compositional Consistency for Video Question Answering</a><time datetime="2022-09-03T07:28:11.000Z" title="发表于 2022-09-03 15:28:11">2022-09-03</time></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div id="footer_deal"><a class="deal_link" href="mailto:kunhaofu1@gmail.com" title="email"><i class="anzhiyufont anzhiyu-icon-envelope"></i></a><a class="deal_link" href="/atom.xml" title="RSS"><i class="anzhiyufont anzhiyu-icon-rss"></i></a><img class="footer_mini_logo" title="返回顶部" alt="返回顶部" onclick="anzhiyu.scrollToDest(0, 500)" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne.gitee.io/kuhne.gitee.io/img/head.jpg" size="50px"/><a class="deal_link" target="_blank" rel="noopener" href="https://github.com/kuhne12" title="Github"><i class="anzhiyufont anzhiyu-icon-github"></i></a><a class="deal_link" href="/copyright" title="CC"><i class="anzhiyufont anzhiyu-icon-copyright-line"></i></a></div><div id="anzhiyu-footer"><div class="footer-group"><div class="footer-title">服务</div><div class="footer-links"><a class="footer-item" title="等待开发" href="/wait/">等待开发</a></div></div><div class="footer-group"><div class="footer-title">主题</div><div class="footer-links"><a class="footer-item" title="文档" href="/docs/">文档</a></div></div><div class="footer-group"><div class="footer-title">导航</div><div class="footer-links"><a class="footer-item" title="等待开发" href="/wait/">等待开发</a></div></div><div class="footer-group"><div class="footer-title">协议</div><div class="footer-links"><a class="footer-item" title="隐私协议" href="/privacy/">隐私协议</a></div></div></div><div id="workboard"><img class="workSituationImg boardsign" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2023/09/07/20230907103822-7fe708.svg" alt="距离月入25k也就还差一个大佬带我~" title="距离月入25k也就还差一个大佬带我~"/><div id="runtimeTextTip"></div></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo_v5.4.0" title="博客框架为Hexo_v5.4.0"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@2.1.5/img/badge/Frame-Hexo.svg" alt="博客框架为Hexo_v5.4.0"/></a><a class="github-badge" target="_blank" href="https://blog.anheyu.com/" style="margin-inline:5px" data-title="本站使用AnZhiYu主题" title="本站使用AnZhiYu主题"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.9/img/Theme-AnZhiYu-2E67D3.svg" alt="本站使用AnZhiYu主题"/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" data-title="本站项目由Github托管" title="本站项目由Github托管"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@2.1.5/img/badge/Source-Github.svg" alt="本站项目由Github托管"/></a><a class="github-badge" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" data-title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可" title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@2.2.0/img/badge/Copyright-BY-NC-SA.svg" alt="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"/></a><a class="github-badge" target="_blank" href="https://beian.miit.gov.cn/" style="margin-inline:5px" data-title="本站已在浙备案" title="本站已在浙备案"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2023/09/07/20230907104640-663234.svg" alt="本站已在浙备案"/></a></p></div><div id="footer-bar"><div class="footer-bar-links"><div class="footer-bar-left"><div id="footer-bar-tips"><div class="copyright">&copy;2020 - 2023 By <a class="footer-bar-link" href="/" title="Kuhne" target="_blank">Kuhne</a></div></div><div id="footer-type-tips"></div></div><div class="footer-bar-right"><a class="footer-bar-link" target="_blank" rel="noopener" href="https://beian.miit.gov.cn/" title="浙ICP备2023005409号-1">浙ICP备2023005409号-1</a><a class="footer-bar-link cc" href="/copyright" title="cc协议"><i class="anzhiyufont anzhiyu-icon-copyright-line"></i><i class="anzhiyufont anzhiyu-icon-creative-commons-by-line"></i><i class="anzhiyufont anzhiyu-icon-creative-commons-nc-line"></i><i class="anzhiyufont anzhiyu-icon-creative-commons-nd-line"></i></a></div></div></div></footer></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="sidebar-site-data site-data is-center"><a href="/archives/" title="archive"><div class="headline">文章</div><div class="length-num">75</div></a><a href="/tags/" title="tag"><div class="headline">标签</div><div class="length-num">31</div></a><a href="/categories/" title="category"><div class="headline">分类</div><div class="length-num">8</div></a></div><span class="sidebar-menu-item-title">功能</span><div class="sidebar-menu-item"><a class="darkmode_switchbutton menu-child" href="javascript:void(0);" title="显示模式"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span>显示模式</span></a></div><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://blog.anheyu.com/" title="博客"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/favicon.ico" alt="博客"/><span class="back-menu-item-text">博客</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">项目</div><div class="back-menu-list"><a class="back-menu-item" href="/null" title="暂无"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://image.anheyu.com/favicon.ico" alt="暂无"/><span class="back-menu-item-text">暂无</span></a></div></div></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/music/?id=883682303&amp;server=netease&amp;type=playlist"><i class="anzhiyufont anzhiyu-icon-music faa-tada" style="font-size: 0.9em;"></i><span> 音乐馆</span></a></li></ul></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/essay/"><span> 闲言碎语</span></a></div></div><span class="sidebar-menu-item-title">标签</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/2022CVPR/" style="font-size: 0.88rem;">2022CVPR<sup>2</sup></a><a href="/tags/Git/" style="font-size: 0.88rem;">Git<sup>1</sup></a><a href="/tags/Kaggle/" style="font-size: 0.88rem;">Kaggle<sup>2</sup></a><a href="/tags/Linux/" style="font-size: 0.88rem;">Linux<sup>2</sup></a><a href="/tags/PyTorch/" style="font-size: 0.88rem;">PyTorch<sup>9</sup></a><a href="/tags/Python/" style="font-size: 0.88rem;">Python<sup>6</sup></a><a href="/tags/Pytorch/" style="font-size: 0.88rem;">Pytorch<sup>1</sup></a><a href="/tags/SpringCloud/" style="font-size: 0.88rem;">SpringCloud<sup>9</sup></a><a href="/tags/Vue/" style="font-size: 0.88rem;">Vue<sup>3</sup></a><a href="/tags/nginx/" style="font-size: 0.88rem;">nginx<sup>1</sup></a><a href="/tags/pycharm/" style="font-size: 0.88rem;">pycharm<sup>1</sup></a><a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" style="font-size: 0.88rem; font-weight: 500; color: var(--anzhiyu-lighttext)">人工智能<sup>21</sup></a><a href="/tags/%E4%BD%9C%E4%B8%9A/" style="font-size: 0.88rem;">作业<sup>8</sup></a><a href="/tags/%E5%8A%A0%E5%AF%86/" style="font-size: 0.88rem;">加密<sup>1</sup></a><a href="/tags/%E5%90%8E%E7%AB%AF/" style="font-size: 0.88rem;">后端<sup>3</sup></a><a href="/tags/%E5%9F%BA%E7%A1%80/" style="font-size: 0.88rem;">基础<sup>12</sup></a><a href="/tags/%E5%B7%A5%E5%85%B7/" style="font-size: 0.88rem;">工具<sup>3</sup></a><a href="/tags/%E5%BD%92%E7%BA%B3/" style="font-size: 0.88rem;">归纳<sup>3</sup></a><a href="/tags/%E6%95%99%E7%A8%8B/" style="font-size: 0.88rem;">教程<sup>10</sup></a><a href="/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/" style="font-size: 0.88rem;">服务器<sup>1</sup></a><a href="/tags/%E6%9C%AA%E5%AE%8C%E6%88%90/" style="font-size: 0.88rem;">未完成<sup>1</sup></a><a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 0.88rem;">机器学习<sup>21</sup></a><a href="/tags/%E6%A8%A1%E5%9E%8B%E5%A4%8D%E7%8E%B0/" style="font-size: 0.88rem;">模型复现<sup>8</sup></a><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 0.88rem; font-weight: 500; color: var(--anzhiyu-lighttext)">深度学习<sup>15</sup></a><a href="/tags/%E7%BD%91%E9%A1%B5%E5%89%8D%E7%AB%AF/" style="font-size: 0.88rem;">网页前端<sup>4</sup></a><a href="/tags/%E8%80%83%E7%A0%94/" style="font-size: 0.88rem;">考研<sup>1</sup></a><a href="/tags/%E8%A7%86%E8%A7%89%E5%85%B3%E7%B3%BB%E6%8E%A2%E6%B5%8B/" style="font-size: 0.88rem;">视觉关系探测<sup>1</sup></a><a href="/tags/%E8%A7%86%E8%A7%89%E9%97%AE%E7%AD%94/" style="font-size: 0.88rem;">视觉问答<sup>1</sup></a><a href="/tags/%E8%A7%86%E9%A2%91%E9%97%AE%E7%AD%94/" style="font-size: 0.88rem;">视频问答<sup>1</sup></a><a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" style="font-size: 0.88rem;">计算机视觉<sup>12</sup></a><a href="/tags/%E8%AE%BA%E6%96%87/" style="font-size: 0.88rem;">论文<sup>4</sup></a></div></div><hr/></div></div><div id="keyboard-tips"><div class="keyboardTitle">博客快捷键</div><div class="keybordList"><div class="keybordItem"><div class="keyGroup"><div class="key">shift K</div></div><div class="keyContent"><div class="content">关闭快捷键功能</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift A</div></div><div class="keyContent"><div class="content">打开/关闭中控台</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift M</div></div><div class="keyContent"><div class="content">播放/暂停音乐</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift D</div></div><div class="keyContent"><div class="content">深色/浅色显示模式</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift S</div></div><div class="keyContent"><div class="content">站内搜索</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift R</div></div><div class="keyContent"><div class="content">随机访问</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift H</div></div><div class="keyContent"><div class="content">返回首页</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift F</div></div><div class="keyContent"><div class="content">友链鱼塘</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift L</div></div><div class="keyContent"><div class="content">友链页面</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift P</div></div><div class="keyContent"><div class="content">关于本站</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift I</div></div><div class="keyContent"><div class="content">原版/本站右键菜单</div></div></div></div></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="anzhiyufont anzhiyu-icon-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="anzhiyufont anzhiyu-icon-gear"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="anzhiyufont anzhiyu-icon-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="anzhiyufont anzhiyu-icon-comments"></i></a><a id="switch-commentBarrage" href="javascript:anzhiyu.switchCommentBarrage();" title="开关弹幕"><i class="anzhiyufont anzhiyu-icon-danmu"></i></a><button id="go-up" type="button" title="回到顶部"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></button></div></div><div id="nav-music"><a id="nav-music-hoverTips" onclick="anzhiyu.musicToggle()" accesskey="m">播放音乐</a><div id="console-music-bg"></div><meting-js id="60198" server="netease" type="playlist" mutex="true" preload="none" theme="var(--anzhiyu-main)" data-lrctype="0" order="random"></meting-js></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="anzhiyufont anzhiyu-icon-xmark"></i></button></nav><div class="is-center" id="loading-database"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-pulse-icon"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="anzhiyufont anzhiyu-icon-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="anzhiyufont anzhiyu-icon-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right" style="font-size: 1rem;"></i></div><div class="rightMenu-item" id="menu-top"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></div></div><div class="rightMenu-group rightMenu-line rightMenuPlugin"><div class="rightMenu-item" id="menu-copytext"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制选中文本</span></div><div class="rightMenu-item" id="menu-pastetext"><i class="anzhiyufont anzhiyu-icon-paste"></i><span>粘贴文本</span></div><a class="rightMenu-item" id="menu-commenttext"><i class="anzhiyufont anzhiyu-icon-comment-medical"></i><span>引用到评论</span></a><div class="rightMenu-item" id="menu-newwindow"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开</span></div><div class="rightMenu-item" id="menu-copylink"><i class="anzhiyufont anzhiyu-icon-link"></i><span>复制链接地址</span></div><div class="rightMenu-item" id="menu-copyimg"><i class="anzhiyufont anzhiyu-icon-images"></i><span>复制此图片</span></div><div class="rightMenu-item" id="menu-downloadimg"><i class="anzhiyufont anzhiyu-icon-download"></i><span>下载此图片</span></div><div class="rightMenu-item" id="menu-newwindowimg"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开图片</span></div><div class="rightMenu-item" id="menu-search"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>站内搜索</span></div><div class="rightMenu-item" id="menu-searchBaidu"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>百度搜索</span></div><div class="rightMenu-item" id="menu-music-toggle"><i class="anzhiyufont anzhiyu-icon-play"></i><span>播放音乐</span></div><div class="rightMenu-item" id="menu-music-back"><i class="anzhiyufont anzhiyu-icon-backward"></i><span>切换到上一首</span></div><div class="rightMenu-item" id="menu-music-forward"><i class="anzhiyufont anzhiyu-icon-forward"></i><span>切换到下一首</span></div><div class="rightMenu-item" id="menu-music-playlist" onclick="window.open(&quot;https://music.163.com/#/playlist&quot;, &quot;_blank&quot;);" style="display: none;"><i class="anzhiyufont anzhiyu-icon-radio"></i><span>查看所有歌曲</span></div><div class="rightMenu-item" id="menu-music-copyMusicName"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制歌名</span></div></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" id="menu-randomPost"><i class="anzhiyufont anzhiyu-icon-shuffle"></i><span>随便逛逛</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="anzhiyufont anzhiyu-icon-cube"></i><span>博客分类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags"></i><span>文章标签</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item" id="menu-copy" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制地址</span></a><a class="rightMenu-item" id="menu-commentBarrage" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-message"></i><span class="menu-commentBarrage-text">关闭热评</span></a><a class="rightMenu-item" id="menu-darkmode" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span class="menu-darkmode-text">深色模式</span></a><a class="rightMenu-item" id="menu-translate" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-language"></i><span>轉為繁體</span></a></div></div><div id="rightmenu-mask"></div><div id="he-plugin-simple"></div><script>var WIDGET = {
  "CONFIG": {
    "modules": "0124",
    "background": "2",
    "tmpColor": "FFFFFF",
    "tmpSize": "16",
    "cityColor": "FFFFFF",
    "citySize": "16",
    "aqiColor": "E8D87B",
    "aqiSize": "16",
    "weatherIconSize": "24",
    "alertIconSize": "18",
    "padding": "10px 10px 10px 10px",
    "shadow": "0",
    "language": "auto",
    "borderRadius": "20",
    "fixed": "true",
    "vertical": "top",
    "horizontal": "left",
    "left": "20",
    "top": "7.1",
    "key": "df245676fb434a0691ead1c63341cd94"
  }
}
</script><link rel="stylesheet" href="https://widget.qweather.net/simple/static/css/he-simple.css?v=1.4.0"/><script src="https://widget.qweather.net/simple/static/js/he-simple.js?v=1.4.0"></script><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.cbd.int/@fancyapps/ui@5.0.20/dist/fancybox/fancybox.umd.js"></script><script src="https://cdn.cbd.int/instant.page@5.2.0/instantpage.js" type="module"></script><script src="https://cdn.cbd.int/vanilla-lazyload@17.8.4/dist/lazyload.iife.min.js"></script><script src="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.js"></script><canvas id="universe"></canvas><script async src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/dark/dark.js"></script><script async src="/anzhiyu/random.js"></script><script async="async">(function () {
  var grt = new Date("04/01/2021 00:00:00"); //设置网站上线时间
  var now = new Date();
  var dnum;
  var hnum;
  var mnum;
  var snum;
  var nowHour;

  // 计算并更新天数、小时数、分钟数和秒数
  function updateTime() {
    now = new Date(); // 更新 now 的值
    nowHour = now.getHours(); // 更新 nowHour 的值
    var days = (now - grt) / 1000 / 60 / 60 / 24;
    dnum = Math.floor(days);
    var hours = (now - grt) / 1000 / 60 / 60 - 24 * dnum;
    hnum = Math.floor(hours);
    if (String(hnum).length == 1) {
      hnum = "0" + hnum;
    }
    var minutes = (now - grt) / 1000 / 60 - 24 * 60 * dnum - 60 * hnum;
    mnum = Math.floor(minutes);
    if (String(mnum).length == 1) {
      mnum = "0" + mnum;
    }
    var seconds = (now - grt) / 1000 - 24 * 60 * 60 * dnum - 60 * 60 * hnum - 60 * mnum;
    snum = Math.round(seconds);
    if (String(snum).length == 1) {
      snum = "0" + snum;
    }
  }

  // 更新网页中显示的网站运行时间
  function updateHtml() {
    const footer = document.getElementById("footer");
    if (!footer) return
    let currentTimeHtml = "";
    if (nowHour < 18 && nowHour >= 9) {
      // 如果是上班时间，默认就是"安知鱼-上班摸鱼中.svg"图片，不需要更改
      currentTimeHtml = `本站居然运行了 ${dnum} 天<span id='runtime'> ${hnum} 小时 ${mnum} 分 ${snum} 秒 </span><i class='anzhiyufont anzhiyu-icon-heartbeat' style='color:red'></i>`;
    } else {
      // 如果是下班时间，插入"安知鱼-下班啦.svg"图片
      let img = document.querySelector("#workboard .workSituationImg");
      img.src = "https://kuhne-blog-img.oss-cn-hangzhou.aliyuncs.com/blog/article-img/2023/09/07/20230907103822-7fe708.svg";
      img.title = "下班了就该开开心心的玩耍，嘿嘿~";
      img.alt = "下班了就该开开心心的玩耍，嘿嘿~";

      currentTimeHtml = `本站居然运行了 ${dnum} 天<span id='runtime'> ${hnum} 小时 ${mnum} 分 ${snum} 秒 </span><i class='anzhiyufont anzhiyu-icon-heartbeat' style='color:red'></i>`;
    }

    if (document.getElementById("runtimeTextTip")) {
      document.getElementById("runtimeTextTip").innerHTML = currentTimeHtml;
    }
  }

  setInterval(() => {
    updateTime();
    updateHtml();
  }, 1000);
})();</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.cbd.int/katex@0.16.0/dist/katex.min.css"><script src="https://cdn.cbd.int/katex@0.16.0/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    anzhiyu.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>(() => {
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://twikoo-api-pearl.vercel.app',
      region: '',
      onCommentLoaded: () => {
        anzhiyu.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') setTimeout(runFn,0)
    else getScript('https://cdn.cbd.int/twikoo@1.6.18/dist/twikoo.all.min.js').then(runFn)
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://twikoo-api-pearl.vercel.app',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  const runFn = () => {
    init();
    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) anzhiyu.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else {
      loadTwikoo()
    }
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script><input type="hidden" name="page-type" id="page-type" value="post"><script async src="/js/anzhiyu/comment_barrage.js"></script></div><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getComment = () => {
    const runTwikoo = () => {
      twikoo.getRecentComments({
        envId: 'https://twikoo-api-pearl.vercel.app',
        region: '',
        pageSize: 6,
        includeReply: true
      }).then(function (res) {
        const twikooArray = res.map(e => {
          return {
            'content': changeContent(e.comment),
            'avatar': e.avatar,
            'nick': e.nick,
            'url': e.url + '#' + e.id,
            'date': new Date(e.created).toISOString()
          }
        })

        saveToLocal.set('twikoo-newest-comments', JSON.stringify(twikooArray), 10/(60*24))
        generateHtml(twikooArray)
      }).catch(function (err) {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.textContent= "无法获取评论，请确认相关配置是否正确"
      })
    }

    if (typeof twikoo === 'object') {
      runTwikoo()
    } else {
      getScript('https://cdn.cbd.int/twikoo@1.6.18/dist/twikoo.all.min.js').then(runTwikoo)
    }
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'><div class='name'><span>${array[i].nick} </span></div></a>`
        }
        
        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <time datetime="${array[i].date}">${anzhiyu.diffDate(array[i].date, true)}</time></div>
        </div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom.innerHTML= result
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('twikoo-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><script>var visitorMail = "visitor@anheyu.com";
</script><script async data-pjax src="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/waterfall/waterfall.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/qrcodejs/1.0.0/qrcode.min.js"></script><script src="/js/anzhiyu/right_click_menu.js"></script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.9/icon/ali_iconfont_css.css"><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/aplayer/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.cbd.int/anzhiyu-blog-static@1.0.1/js/APlayer.min.js"></script><script src="https://cdn.cbd.int/hexo-anzhiyu-music@1.0.1/assets/js/Meting2.min.js"></script><script src="https://cdn.cbd.int/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["meta[property=\"og:image\"]","meta[property=\"og:title\"]","meta[property=\"og:url\"]","meta[property=\"og:type\"]","meta[property=\"og:site_name\"]","meta[property=\"og:description\"]","head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]
var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {
  // removeEventListener scroll 
  anzhiyu.removeGlobalFnEvent('pjax')
  anzhiyu.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script charset="UTF-8" src="https://cdn.cbd.int/anzhiyu-theme-static@1.1.5/accesskey/accesskey.js"></script></div><div id="popup-window"><div class="popup-window-title">通知</div><div class="popup-window-divider"></div><div class="popup-window-content"><div class="popup-tip">你好呀</div><div class="popup-link"><i class="anzhiyufont anzhiyu-icon-arrow-circle-right"></i></div></div></div></body></html>